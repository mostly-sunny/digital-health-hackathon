{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "coxph-find-best-network.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mostly-sunny/digital-health-hackathon/blob/main/3.%20coxph_find_best_network_by_gpu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L91UX-HYY5Qr"
      },
      "source": [
        "# Pycox - CoxPH Model\n",
        "- Network : Test with sets, and find best network and lr by lowest brier score\n",
        "- Input Variables : G1 ~ G300, Var1 ~ Var10, Treatment\n",
        "- Output Variables : time, event\n",
        "- Scaler : MinMaxScaler -> Var1 ~ Var10\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlcJyLq91wdA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f486b52-610f-418b-8e54-3ccc780b1937"
      },
      "source": [
        "pip install pycox"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n",
            "Requirement already satisfied: pycox in /usr/local/lib/python3.7/dist-packages (0.2.2)\n",
            "Requirement already satisfied: py7zr>=0.11.3 in /usr/local/lib/python3.7/dist-packages (from pycox) (0.16.1)\n",
            "Requirement already satisfied: numba>=0.44 in /usr/local/lib/python3.7/dist-packages (from pycox) (0.51.2)\n",
            "Requirement already satisfied: feather-format>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from pycox) (0.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.21.2 in /usr/local/lib/python3.7/dist-packages (from pycox) (0.22.2.post1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from pycox) (3.1.0)\n",
            "Requirement already satisfied: torchtuples>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from pycox) (0.2.2)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.7/dist-packages (from pycox) (2.23.0)\n",
            "Requirement already satisfied: pyarrow>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from feather-format>=0.4.0->pycox) (3.0.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->pycox) (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->pycox) (1.19.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.44->pycox) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.44->pycox) (0.34.0)\n",
            "Requirement already satisfied: pycryptodomex>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from py7zr>=0.11.3->pycox) (3.10.4)\n",
            "Requirement already satisfied: bcj-cffi<0.6.0,>=0.5.1 in /usr/local/lib/python3.7/dist-packages (from py7zr>=0.11.3->pycox) (0.5.1)\n",
            "Requirement already satisfied: texttable in /usr/local/lib/python3.7/dist-packages (from py7zr>=0.11.3->pycox) (1.6.4)\n",
            "Requirement already satisfied: multivolumefile>=0.2.3 in /usr/local/lib/python3.7/dist-packages (from py7zr>=0.11.3->pycox) (0.2.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from py7zr>=0.11.3->pycox) (4.8.1)\n",
            "Requirement already satisfied: pyzstd<0.15.0,>=0.14.4 in /usr/local/lib/python3.7/dist-packages (from py7zr>=0.11.3->pycox) (0.14.4)\n",
            "Requirement already satisfied: brotli>=1.0.9 in /usr/local/lib/python3.7/dist-packages (from py7zr>=0.11.3->pycox) (1.0.9)\n",
            "Requirement already satisfied: pyppmd>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from py7zr>=0.11.3->pycox) (0.17.0)\n",
            "Requirement already satisfied: cffi>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from bcj-cffi<0.6.0,>=0.5.1->py7zr>=0.11.3->pycox) (1.14.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.14.0->bcj-cffi<0.6.0,>=0.5.1->py7zr>=0.11.3->pycox) (2.20)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->pycox) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->pycox) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->pycox) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->pycox) (3.0.4)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.2->pycox) (1.0.1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.2->pycox) (1.4.1)\n",
            "Requirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.7/dist-packages (from torchtuples>=0.2.0->pycox) (1.1.5)\n",
            "Requirement already satisfied: matplotlib>=3.0.3 in /usr/local/lib/python3.7/dist-packages (from torchtuples>=0.2.0->pycox) (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.3->torchtuples>=0.2.0->pycox) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.3->torchtuples>=0.2.0->pycox) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.3->torchtuples>=0.2.0->pycox) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.3->torchtuples>=0.2.0->pycox) (2.8.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib>=3.0.3->torchtuples>=0.2.0->pycox) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.2->torchtuples>=0.2.0->pycox) (2018.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->py7zr>=0.11.3->pycox) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->py7zr>=0.11.3->pycox) (3.7.4.3)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8j42Q8682S-J"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn_pandas import DataFrameMapper\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchtuples as tt\n",
        "\n",
        "from pycox.models import CoxPH\n",
        "from pycox.evaluation import EvalSurv"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgR8rJ3epF44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67c55e8d-2695-458d-9b4b-db92504a29d6"
      },
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgHuZOMr6wdT"
      },
      "source": [
        "np.random.seed(123456)\n",
        "_ = torch.manual_seed(123456)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOyFOsuvkXqN"
      },
      "source": [
        "- all-in-one.csv 파일은 유전자 변이 유무, 임상 변수, 생존 기간, 사망 여부, 치료 유무가 열로 존재하는 파일\n",
        "- test-data-treat-and-untreat.csv 파일은 all-in-one의 열은 같은 602개의 데이터.\n",
        "  - (0번째 행) : 유전자 변이 모두 0, 치료 0\n",
        "  - (1번째 행) : 유전자 변이 모두 0, 치료 1\n",
        "  - (2~301번째 행) : 유전자 변이 n-1에만 1, 치료 0\n",
        "  - (302~601번재 행) : 유전자 변이 n-301에만 1, 치료 1\n",
        "- pandas 라이브러리에 있는 csv 파일을 DataFrame으로 바꾸어주는 read_csv 함수를 이용하여 파일을 읽어 들임.\n",
        "- DataFrame은 표를 나타내는 데이터 타입임."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3Ww7lpV2Uor"
      },
      "source": [
        "dataset = pd.read_csv('/content/all-in-one.csv')\n",
        "dataset_for_hr = pd.read_csv('/content/test-data-treat-and-untreat.csv')"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twdq_J1Ym9gf"
      },
      "source": [
        "- 위에서 읽어들인 dataset 중에서 20%는 검증(_val -> validation)을 위해 sampling 한다.\n",
        "- 남은 80%의 데이터에서도 20%는 테스트(_test)를 위해 sampling 한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4vLVwYM24xW"
      },
      "source": [
        "dataset_test = dataset.sample(frac=0.3, random_state = np.random.seed(123456))\n",
        "dataset_train = dataset.drop(dataset_test.index)\n",
        "dataset_val = dataset_train.sample(frac=0.2, random_state = np.random.seed(123456))\n",
        "dataset_train = dataset_train.drop(dataset_val.index)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "RXu0kxYzRuc-",
        "outputId": "0ea77344-e79e-457b-ee27-5dfaca9631f7"
      },
      "source": [
        "dataset_train"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>G1</th>\n",
              "      <th>G2</th>\n",
              "      <th>G3</th>\n",
              "      <th>G4</th>\n",
              "      <th>G5</th>\n",
              "      <th>G6</th>\n",
              "      <th>G7</th>\n",
              "      <th>G8</th>\n",
              "      <th>G9</th>\n",
              "      <th>G10</th>\n",
              "      <th>G11</th>\n",
              "      <th>G12</th>\n",
              "      <th>G13</th>\n",
              "      <th>G14</th>\n",
              "      <th>G15</th>\n",
              "      <th>G16</th>\n",
              "      <th>G17</th>\n",
              "      <th>G18</th>\n",
              "      <th>G19</th>\n",
              "      <th>G20</th>\n",
              "      <th>G21</th>\n",
              "      <th>G22</th>\n",
              "      <th>G23</th>\n",
              "      <th>G24</th>\n",
              "      <th>G25</th>\n",
              "      <th>G26</th>\n",
              "      <th>G27</th>\n",
              "      <th>G28</th>\n",
              "      <th>G29</th>\n",
              "      <th>G30</th>\n",
              "      <th>G31</th>\n",
              "      <th>G32</th>\n",
              "      <th>G33</th>\n",
              "      <th>G34</th>\n",
              "      <th>G35</th>\n",
              "      <th>G36</th>\n",
              "      <th>G37</th>\n",
              "      <th>G38</th>\n",
              "      <th>G39</th>\n",
              "      <th>G40</th>\n",
              "      <th>...</th>\n",
              "      <th>G274</th>\n",
              "      <th>G275</th>\n",
              "      <th>G276</th>\n",
              "      <th>G277</th>\n",
              "      <th>G278</th>\n",
              "      <th>G279</th>\n",
              "      <th>G280</th>\n",
              "      <th>G281</th>\n",
              "      <th>G282</th>\n",
              "      <th>G283</th>\n",
              "      <th>G284</th>\n",
              "      <th>G285</th>\n",
              "      <th>G286</th>\n",
              "      <th>G287</th>\n",
              "      <th>G288</th>\n",
              "      <th>G289</th>\n",
              "      <th>G290</th>\n",
              "      <th>G291</th>\n",
              "      <th>G292</th>\n",
              "      <th>G293</th>\n",
              "      <th>G294</th>\n",
              "      <th>G295</th>\n",
              "      <th>G296</th>\n",
              "      <th>G297</th>\n",
              "      <th>G298</th>\n",
              "      <th>G299</th>\n",
              "      <th>G300</th>\n",
              "      <th>Var1</th>\n",
              "      <th>Var2</th>\n",
              "      <th>Var3</th>\n",
              "      <th>Var4</th>\n",
              "      <th>Var5</th>\n",
              "      <th>Var6</th>\n",
              "      <th>Var7</th>\n",
              "      <th>Var8</th>\n",
              "      <th>Var9</th>\n",
              "      <th>Var10</th>\n",
              "      <th>time</th>\n",
              "      <th>event</th>\n",
              "      <th>Treatment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>57.448331</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>44.559284</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>68.660751</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>53.705056</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>94.614254</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>988</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>59.763248</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>991</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>62.919174</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>66.591235</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>62.986021</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>36.714493</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>559 rows × 313 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     G1  G2  G3  G4  G5  G6  ...  Var8  Var9  Var10       time  event  Treatment\n",
              "0     0   1   0   0   0   0  ...     1     0      1  57.448331      1          0\n",
              "4     0   0   0   0   0   0  ...     3     3      1  44.559284      0          0\n",
              "6     0   0   0   0   0   0  ...     2     6      2  68.660751      1          0\n",
              "7     0   0   0   1   0   0  ...     1     3      1  53.705056      1          1\n",
              "9     0   0   0   0   0   0  ...     4     1      0  94.614254      1          1\n",
              "..   ..  ..  ..  ..  ..  ..  ...   ...   ...    ...        ...    ...        ...\n",
              "988   0   0   0   0   0   1  ...     3     0      1  59.763248      1          0\n",
              "991   0   0   0   1   0   1  ...     4     4      2  62.919174      1          0\n",
              "995   0   0   0   0   0   0  ...     1     4      4  66.591235      1          1\n",
              "996   0   0   0   0   0   0  ...     4     2      0  62.986021      0          1\n",
              "998   0   0   0   0   0   0  ...     2     1      3  36.714493      1          0\n",
              "\n",
              "[559 rows x 313 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UX1Ddl463deJ"
      },
      "source": [
        "- columns_standardize : 임상변수 - 0~9사이의 값을 표준화\n",
        "- columns_leave : 유전자 변이 유무 + 치료 유무 - 0과 1로 표현돼 있기 때문에 표준화 필요 없음.\n",
        "- DataFrameMapper는 pandas DataFrame에서 원하는 열을 뽑아서 리스트로 만들어줌.\n",
        "- 리스트로 만들때 StandardScaler()가 포함된 열은 표준화를 시킨 뒤, 그리고 None이면 갖고 있는 값을 그대로 넣음."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHBg3yDH3Xzf"
      },
      "source": [
        "columns_standardize = ['Var' + str(i) for i in range(1,11)]\n",
        "columns_leave = ['G' + str(i) for i in range(1,301)]\n",
        "columns_leave += ['Treatment']\n",
        "\n",
        "# standardize = [([col], StandardScaler()) for col in columns_standardize]\n",
        "standardize = [([col], MinMaxScaler()) for col in columns_standardize]\n",
        "\n",
        "leave = [(col, None) for col in columns_leave]\n",
        "\n",
        "x_mapper = DataFrameMapper(leave + standardize)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZHTUBBSmWTc"
      },
      "source": [
        "- 위에서 만든 DataFrameMapper로 DataFrame 중 x(입력) 데이터를 모델이 학습할 수 있게끔 리스트 형식으로 바꾸어 준다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4UrVswf3phZ"
      },
      "source": [
        "x_train = x_mapper.fit_transform(dataset_train).astype('float32')\n",
        "x_val = x_mapper.transform(dataset_val).astype('float32')\n",
        "x_test = x_mapper.transform(dataset_test).astype('float32')\n",
        "x_for_hr = x_mapper.transform(dataset_for_hr).astype('float32')"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4PCVeJGmx21"
      },
      "source": [
        "- DataFrame (표)에서 Y(출력)데이터인 time(생존기간)과 event(사망여부)를 뽑아 출력 데이터를 추린다.\n",
        "- 검증(Validation)을 위한 입력-출력 세트 val을 만든다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGTF5V3y4Yot"
      },
      "source": [
        "get_target = lambda df: (df['time'].values, df['event'].values)\n",
        "y_train = get_target(dataset_train)\n",
        "y_val = get_target(dataset_val)\n",
        "\n",
        "durations_test, events_test = get_target(dataset_test)\n",
        "val = x_val, y_val"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-rPa9mWn1I4"
      },
      "source": [
        "함수 make_net : network을 생성해 리턴하는 함수\n",
        "- input과 output의 노드 수, 은닉층 수, 은닉층의 노드 수 설정 가능"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eauwa8i6iGmN"
      },
      "source": [
        "def make_net(in_features, out_features, hidden, nodes):\n",
        "  if hidden == 1:\n",
        "    network =  torch.nn.Sequential(\n",
        "      torch.nn.Linear(in_features, nodes),\n",
        "      torch.nn.ReLU(),\n",
        "      torch.nn.BatchNorm1d(nodes),\n",
        "      torch.nn.Dropout(0.1),\n",
        "            \n",
        "      torch.nn.Linear(nodes, out_features)\n",
        "    )\n",
        "  elif hidden == 2:\n",
        "    network =  torch.nn.Sequential(\n",
        "      torch.nn.Linear(in_features, nodes),\n",
        "      torch.nn.ReLU(),\n",
        "      torch.nn.BatchNorm1d(nodes),\n",
        "      torch.nn.Dropout(0.1),\n",
        "\n",
        "      torch.nn.Linear(nodes, nodes),\n",
        "      torch.nn.ReLU(),\n",
        "      torch.nn.BatchNorm1d(nodes),\n",
        "      torch.nn.Dropout(0.1),\n",
        "            \n",
        "      torch.nn.Linear(nodes, out_features)\n",
        "    )\n",
        "  elif hidden == 3:\n",
        "    network =  torch.nn.Sequential(\n",
        "      torch.nn.Linear(in_features, nodes),\n",
        "      torch.nn.ReLU(),\n",
        "      torch.nn.BatchNorm1d(nodes),\n",
        "      torch.nn.Dropout(0.1),\n",
        "\n",
        "      torch.nn.Linear(nodes, nodes),\n",
        "      torch.nn.ReLU(),\n",
        "      torch.nn.BatchNorm1d(nodes),\n",
        "      torch.nn.Dropout(0.1),\n",
        "\n",
        "      torch.nn.Linear(nodes, nodes),\n",
        "      torch.nn.ReLU(),\n",
        "      torch.nn.BatchNorm1d(nodes),\n",
        "      torch.nn.Dropout(0.1),\n",
        "            \n",
        "      torch.nn.Linear(nodes, out_features)\n",
        "    )\n",
        "  elif hidden == 4:\n",
        "    network =  torch.nn.Sequential(\n",
        "      torch.nn.Linear(in_features, nodes),\n",
        "      torch.nn.ReLU(),\n",
        "      torch.nn.BatchNorm1d(nodes),\n",
        "      torch.nn.Dropout(0.1),\n",
        "\n",
        "      torch.nn.Linear(nodes, nodes),\n",
        "      torch.nn.ReLU(),\n",
        "      torch.nn.BatchNorm1d(nodes),\n",
        "      torch.nn.Dropout(0.1),\n",
        "\n",
        "      torch.nn.Linear(nodes, nodes),\n",
        "      torch.nn.ReLU(),\n",
        "      torch.nn.BatchNorm1d(nodes),\n",
        "      torch.nn.Dropout(0.1),\n",
        "      \n",
        "      torch.nn.Linear(nodes, nodes),\n",
        "      torch.nn.ReLU(),\n",
        "      torch.nn.BatchNorm1d(nodes),\n",
        "      torch.nn.Dropout(0.1),\n",
        "\n",
        "      torch.nn.Linear(nodes, out_features)\n",
        "    )\n",
        "  return network"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0BBkip4uOx3"
      },
      "source": [
        "- in_features : 입력데이터의 개수 (x_train.shape : 311 = 300(유전자) + 10(임상변수) + 1(치료유무))\n",
        "- out_features : 출력노드의 개수\n",
        "\n",
        "- hidden_layers : 은닉층 수를 가지고 있는 리스트\n",
        "- number_nodes : 은닉층에 있는 노드 수를 가지고 있는 리스트\n",
        "- learning_rates : 테스트할 학습률을 가지고 있는 리스트\n",
        "- brier_scores = brier score을 계산해 append"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJHZogmj5a-4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdebd6b9-ff19-43b3-ac8a-f5cf1b667afa"
      },
      "source": [
        "in_features = x_train.shape[1]\n",
        "out_features = 1\n",
        "\n",
        "hidden_layers = [1,2]\n",
        "number_nodes = [2000, 3000]\n",
        "learning_rates = [0.0001, 0.001, 0]\n",
        "brier_scores = []\n",
        "\n",
        "total_num = len(hidden_layers) * len(number_nodes) * len(learning_rates)\n",
        "count = 1\n",
        "\n",
        "for i in hidden_layers:\n",
        "  for j in number_nodes:\n",
        "    for k in learning_rates:\n",
        "      print(count, '/' , total_num)\n",
        "      net = make_net(in_features, out_features, i, j)\n",
        "      model = CoxPH(net, tt.optim.Adam)\n",
        "      batch_size = 639\n",
        "\n",
        "      if k == 0:\n",
        "        lrfinder = model.lr_finder(x_train, y_train, batch_size, tolerance = 10)\n",
        "        model.optimizer.set_lr(lrfinder.get_best_lr())\n",
        "      else:\n",
        "        model.optimizer.set_lr(k)\n",
        "      \n",
        "      epochs = 512\n",
        "      callbacks = [tt.callbacks.EarlyStopping()]\n",
        "      verbose = True\n",
        "\n",
        "      %%time\n",
        "      model.fit(x_train, y_train, batch_size, epochs, callbacks, verbose, val_data=val, val_batch_size=batch_size)\n",
        "      _ = model.compute_baseline_hazards()\n",
        "      surv = model.predict_surv_df(x_test)\n",
        "\n",
        "      count += 1\n",
        "\n",
        "      # calculate ratio\n",
        "      log_partial_hazard = model.predict(x_for_hr)\n",
        "      partial_hazard = [np.exp(lph) for lph in log_partial_hazard]\n",
        "\n",
        "      treat_hr = []\n",
        "      # ratio with treated and untreated\n",
        "      for g in range(300):\n",
        "        treat_hr.append([partial_hazard[g+302]/partial_hazard[g+2],'G' + str(g+1)])\n",
        "      treat_hr.sort()\n",
        "\n",
        "      # evaluation\n",
        "      ev = EvalSurv(surv, durations_test, events_test, censor_surv='km')\n",
        "      time_grid = np.linspace(durations_test.min(), durations_test.max(), 100)\n",
        "      score = ev.integrated_brier_score(time_grid)\n",
        "\n",
        "      if k == 0:\n",
        "        brier_scores.append([score, i, j, lrfinder.get_best_lr(), treat_hr[:10]])\n",
        "      else:\n",
        "        brier_scores.append([score, i, j, k, treat_hr[:10]])"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 / 12\n",
            "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
            "Wall time: 5.72 µs\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 5.4748,\tval_loss: 3.9832\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 5.4014,\tval_loss: 3.9821\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 5.3513,\tval_loss: 3.9808\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 5.2618,\tval_loss: 3.9794\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 5.2251,\tval_loss: 3.9779\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 5.1673,\tval_loss: 3.9761\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 5.1139,\tval_loss: 3.9743\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 5.0800,\tval_loss: 3.9723\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 5.0425,\tval_loss: 3.9703\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.9893,\tval_loss: 3.9680\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.9635,\tval_loss: 3.9657\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.9261,\tval_loss: 3.9632\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.9023,\tval_loss: 3.9605\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.8599,\tval_loss: 3.9577\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 4.8345,\tval_loss: 3.9547\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 4.8000,\tval_loss: 3.9515\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 4.7757,\tval_loss: 3.9481\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 4.7420,\tval_loss: 3.9446\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 4.7296,\tval_loss: 3.9409\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 4.6790,\tval_loss: 3.9371\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 4.6541,\tval_loss: 3.9331\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 4.6305,\tval_loss: 3.9291\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 4.6131,\tval_loss: 3.9250\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 4.5922,\tval_loss: 3.9207\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 4.5668,\tval_loss: 3.9164\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 4.5372,\tval_loss: 3.9119\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 4.5125,\tval_loss: 3.9076\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 4.4885,\tval_loss: 3.9033\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 4.4722,\tval_loss: 3.8992\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 4.4405,\tval_loss: 3.8952\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 4.4235,\tval_loss: 3.8914\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 4.4055,\tval_loss: 3.8877\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 4.3770,\tval_loss: 3.8842\n",
            "33:\t[0s / 2s],\t\ttrain_loss: 4.3450,\tval_loss: 3.8808\n",
            "34:\t[0s / 2s],\t\ttrain_loss: 4.3425,\tval_loss: 3.8779\n",
            "35:\t[0s / 2s],\t\ttrain_loss: 4.3119,\tval_loss: 3.8754\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 4.2963,\tval_loss: 3.8732\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 4.2741,\tval_loss: 3.8713\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 4.2591,\tval_loss: 3.8702\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 4.2445,\tval_loss: 3.8695\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 4.2248,\tval_loss: 3.8692\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 4.1947,\tval_loss: 3.8695\n",
            "42:\t[0s / 2s],\t\ttrain_loss: 4.1846,\tval_loss: 3.8703\n",
            "43:\t[0s / 2s],\t\ttrain_loss: 4.1654,\tval_loss: 3.8719\n",
            "44:\t[0s / 2s],\t\ttrain_loss: 4.1486,\tval_loss: 3.8742\n",
            "45:\t[0s / 2s],\t\ttrain_loss: 4.1269,\tval_loss: 3.8770\n",
            "46:\t[0s / 2s],\t\ttrain_loss: 4.1052,\tval_loss: 3.8806\n",
            "47:\t[0s / 2s],\t\ttrain_loss: 4.0872,\tval_loss: 3.8851\n",
            "48:\t[0s / 2s],\t\ttrain_loss: 4.0693,\tval_loss: 3.8901\n",
            "49:\t[0s / 2s],\t\ttrain_loss: 4.0507,\tval_loss: 3.8956\n",
            "50:\t[0s / 2s],\t\ttrain_loss: 4.0373,\tval_loss: 3.9017\n",
            "2 / 12\n",
            "CPU times: user 5 µs, sys: 1e+03 ns, total: 6 µs\n",
            "Wall time: 11.9 µs\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 5.4816,\tval_loss: 3.9683\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 5.0355,\tval_loss: 3.9576\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.7655,\tval_loss: 3.9457\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.5562,\tval_loss: 3.9335\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.3664,\tval_loss: 3.9215\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.2043,\tval_loss: 3.9102\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.0747,\tval_loss: 3.8992\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 3.9472,\tval_loss: 3.8878\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 3.8392,\tval_loss: 3.8759\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 3.7585,\tval_loss: 3.8646\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 3.7510,\tval_loss: 3.8537\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 3.6667,\tval_loss: 3.8444\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 3.5564,\tval_loss: 3.8339\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 3.5372,\tval_loss: 3.8239\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 3.5274,\tval_loss: 3.8157\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 3.5420,\tval_loss: 3.8093\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 3.5488,\tval_loss: 3.8067\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.5903,\tval_loss: 3.8097\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.6564,\tval_loss: 3.8145\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.6599,\tval_loss: 3.8266\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.6217,\tval_loss: 3.8426\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.6883,\tval_loss: 3.8628\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.6441,\tval_loss: 3.8858\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.6421,\tval_loss: 3.9026\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.6591,\tval_loss: 3.9171\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 3.6731,\tval_loss: 3.9349\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 3.6463,\tval_loss: 3.9527\n",
            "3 / 12\n",
            "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
            "Wall time: 5.72 µs\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 5.3970,\tval_loss: 3.9617\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 4.9271,\tval_loss: 3.9496\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.5143,\tval_loss: 3.9334\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.2566,\tval_loss: 3.9154\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.0481,\tval_loss: 3.8967\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 3.9107,\tval_loss: 3.8811\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 3.7560,\tval_loss: 3.8666\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 3.6523,\tval_loss: 3.8545\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 3.6475,\tval_loss: 3.8437\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 3.6480,\tval_loss: 3.8348\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 3.6566,\tval_loss: 3.8322\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 3.7434,\tval_loss: 3.8339\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 3.7255,\tval_loss: 3.8344\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 3.6594,\tval_loss: 3.8364\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 3.7126,\tval_loss: 3.8399\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 3.7067,\tval_loss: 3.8421\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 3.7076,\tval_loss: 3.8443\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.7429,\tval_loss: 3.8463\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.7244,\tval_loss: 3.8504\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.7228,\tval_loss: 3.8585\n",
            "20:\t[0s / 0s],\t\ttrain_loss: 3.7060,\tval_loss: 3.8696\n",
            "4 / 12\n",
            "CPU times: user 4 µs, sys: 1e+03 ns, total: 5 µs\n",
            "Wall time: 10.3 µs\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 5.5433,\tval_loss: 3.9988\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 5.4436,\tval_loss: 3.9979\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 5.3602,\tval_loss: 3.9967\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 5.2834,\tval_loss: 3.9956\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 5.2040,\tval_loss: 3.9943\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 5.1441,\tval_loss: 3.9930\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 5.0816,\tval_loss: 3.9915\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 5.0338,\tval_loss: 3.9898\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 4.9875,\tval_loss: 3.9879\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 4.9425,\tval_loss: 3.9859\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 4.9056,\tval_loss: 3.9837\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 4.8529,\tval_loss: 3.9815\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 4.8194,\tval_loss: 3.9791\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 4.7896,\tval_loss: 3.9767\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 4.7369,\tval_loss: 3.9742\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 4.6998,\tval_loss: 3.9715\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 4.6702,\tval_loss: 3.9689\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 4.6491,\tval_loss: 3.9662\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 4.6244,\tval_loss: 3.9636\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 4.5808,\tval_loss: 3.9610\n",
            "20:\t[0s / 0s],\t\ttrain_loss: 4.5434,\tval_loss: 3.9583\n",
            "21:\t[0s / 0s],\t\ttrain_loss: 4.5181,\tval_loss: 3.9558\n",
            "22:\t[0s / 0s],\t\ttrain_loss: 4.4917,\tval_loss: 3.9533\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 4.4626,\tval_loss: 3.9509\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 4.4336,\tval_loss: 3.9485\n",
            "25:\t[0s / 1s],\t\ttrain_loss: 4.3993,\tval_loss: 3.9462\n",
            "26:\t[0s / 1s],\t\ttrain_loss: 4.3766,\tval_loss: 3.9441\n",
            "27:\t[0s / 1s],\t\ttrain_loss: 4.3584,\tval_loss: 3.9422\n",
            "28:\t[0s / 1s],\t\ttrain_loss: 4.3341,\tval_loss: 3.9407\n",
            "29:\t[0s / 1s],\t\ttrain_loss: 4.3104,\tval_loss: 3.9395\n",
            "30:\t[0s / 1s],\t\ttrain_loss: 4.2762,\tval_loss: 3.9388\n",
            "31:\t[0s / 1s],\t\ttrain_loss: 4.2518,\tval_loss: 3.9386\n",
            "32:\t[0s / 1s],\t\ttrain_loss: 4.2307,\tval_loss: 3.9388\n",
            "33:\t[0s / 1s],\t\ttrain_loss: 4.2165,\tval_loss: 3.9396\n",
            "34:\t[0s / 1s],\t\ttrain_loss: 4.1931,\tval_loss: 3.9409\n",
            "35:\t[0s / 1s],\t\ttrain_loss: 4.1693,\tval_loss: 3.9424\n",
            "36:\t[0s / 2s],\t\ttrain_loss: 4.1371,\tval_loss: 3.9445\n",
            "37:\t[0s / 2s],\t\ttrain_loss: 4.1206,\tval_loss: 3.9473\n",
            "38:\t[0s / 2s],\t\ttrain_loss: 4.0969,\tval_loss: 3.9510\n",
            "39:\t[0s / 2s],\t\ttrain_loss: 4.0805,\tval_loss: 3.9556\n",
            "40:\t[0s / 2s],\t\ttrain_loss: 4.0597,\tval_loss: 3.9609\n",
            "41:\t[0s / 2s],\t\ttrain_loss: 4.0426,\tval_loss: 3.9669\n",
            "5 / 12\n",
            "CPU times: user 3 µs, sys: 1e+03 ns, total: 4 µs\n",
            "Wall time: 9.3 µs\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 5.4682,\tval_loss: 3.9818\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 5.0068,\tval_loss: 3.9675\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.7127,\tval_loss: 3.9514\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.4702,\tval_loss: 3.9377\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.2734,\tval_loss: 3.9259\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.1071,\tval_loss: 3.9145\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 3.9573,\tval_loss: 3.9037\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 3.8260,\tval_loss: 3.8927\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 3.7428,\tval_loss: 3.8817\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 3.7551,\tval_loss: 3.8708\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 3.6754,\tval_loss: 3.8609\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 3.5774,\tval_loss: 3.8499\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 3.5598,\tval_loss: 3.8411\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 3.5877,\tval_loss: 3.8363\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 3.6568,\tval_loss: 3.8349\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 3.6038,\tval_loss: 3.8370\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 3.6240,\tval_loss: 3.8415\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 3.5730,\tval_loss: 3.8487\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 3.5855,\tval_loss: 3.8583\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 3.6250,\tval_loss: 3.8683\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.6229,\tval_loss: 3.8740\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.6191,\tval_loss: 3.8837\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.6358,\tval_loss: 3.8933\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.6619,\tval_loss: 3.8968\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.6662,\tval_loss: 3.9032\n",
            "6 / 12\n",
            "CPU times: user 5 µs, sys: 1 µs, total: 6 µs\n",
            "Wall time: 12.9 µs\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 5.4976,\tval_loss: 3.9576\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 5.0278,\tval_loss: 3.9474\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.7670,\tval_loss: 3.9366\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.5751,\tval_loss: 3.9261\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.3670,\tval_loss: 3.9144\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.2098,\tval_loss: 3.9014\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.0646,\tval_loss: 3.8870\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 3.9486,\tval_loss: 3.8724\n",
            "8:\t[0s / 1s],\t\ttrain_loss: 3.8189,\tval_loss: 3.8582\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 3.7296,\tval_loss: 3.8437\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 3.6667,\tval_loss: 3.8304\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 3.6126,\tval_loss: 3.8170\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 3.5570,\tval_loss: 3.8065\n",
            "13:\t[0s / 1s],\t\ttrain_loss: 3.5370,\tval_loss: 3.8001\n",
            "14:\t[0s / 1s],\t\ttrain_loss: 3.5811,\tval_loss: 3.7948\n",
            "15:\t[0s / 1s],\t\ttrain_loss: 3.6572,\tval_loss: 3.7943\n",
            "16:\t[0s / 1s],\t\ttrain_loss: 3.6499,\tval_loss: 3.7955\n",
            "17:\t[0s / 1s],\t\ttrain_loss: 3.6629,\tval_loss: 3.8035\n",
            "18:\t[0s / 1s],\t\ttrain_loss: 3.6220,\tval_loss: 3.8108\n",
            "19:\t[0s / 1s],\t\ttrain_loss: 3.6592,\tval_loss: 3.8208\n",
            "20:\t[0s / 1s],\t\ttrain_loss: 3.6398,\tval_loss: 3.8296\n",
            "21:\t[0s / 1s],\t\ttrain_loss: 3.6304,\tval_loss: 3.8388\n",
            "22:\t[0s / 1s],\t\ttrain_loss: 3.6909,\tval_loss: 3.8443\n",
            "23:\t[0s / 1s],\t\ttrain_loss: 3.6392,\tval_loss: 3.8498\n",
            "24:\t[0s / 1s],\t\ttrain_loss: 3.7480,\tval_loss: 3.8571\n",
            "25:\t[0s / 2s],\t\ttrain_loss: 3.6871,\tval_loss: 3.8682\n",
            "7 / 12\n",
            "CPU times: user 5 µs, sys: 1e+03 ns, total: 6 µs\n",
            "Wall time: 11 µs\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 5.5165,\tval_loss: 3.9776\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 5.2119,\tval_loss: 3.9748\n",
            "2:\t[0s / 1s],\t\ttrain_loss: 4.9877,\tval_loss: 3.9717\n",
            "3:\t[0s / 1s],\t\ttrain_loss: 4.8435,\tval_loss: 3.9683\n",
            "4:\t[0s / 2s],\t\ttrain_loss: 4.6908,\tval_loss: 3.9644\n",
            "5:\t[0s / 2s],\t\ttrain_loss: 4.5648,\tval_loss: 3.9602\n",
            "6:\t[0s / 2s],\t\ttrain_loss: 4.4562,\tval_loss: 3.9554\n",
            "7:\t[0s / 2s],\t\ttrain_loss: 4.3715,\tval_loss: 3.9500\n",
            "8:\t[0s / 3s],\t\ttrain_loss: 4.2669,\tval_loss: 3.9435\n",
            "9:\t[0s / 3s],\t\ttrain_loss: 4.1757,\tval_loss: 3.9363\n",
            "10:\t[0s / 4s],\t\ttrain_loss: 4.1040,\tval_loss: 3.9281\n",
            "11:\t[0s / 4s],\t\ttrain_loss: 4.0402,\tval_loss: 3.9188\n",
            "12:\t[0s / 5s],\t\ttrain_loss: 3.9543,\tval_loss: 3.9087\n",
            "13:\t[0s / 5s],\t\ttrain_loss: 3.9237,\tval_loss: 3.8983\n",
            "14:\t[0s / 5s],\t\ttrain_loss: 3.8687,\tval_loss: 3.8876\n",
            "15:\t[0s / 6s],\t\ttrain_loss: 3.8240,\tval_loss: 3.8767\n",
            "16:\t[0s / 6s],\t\ttrain_loss: 3.7895,\tval_loss: 3.8657\n",
            "17:\t[0s / 7s],\t\ttrain_loss: 3.7878,\tval_loss: 3.8551\n",
            "18:\t[0s / 7s],\t\ttrain_loss: 3.7247,\tval_loss: 3.8452\n",
            "19:\t[0s / 8s],\t\ttrain_loss: 3.6784,\tval_loss: 3.8364\n",
            "20:\t[0s / 8s],\t\ttrain_loss: 3.6382,\tval_loss: 3.8279\n",
            "21:\t[0s / 9s],\t\ttrain_loss: 3.6230,\tval_loss: 3.8203\n",
            "22:\t[0s / 9s],\t\ttrain_loss: 3.6153,\tval_loss: 3.8130\n",
            "23:\t[0s / 9s],\t\ttrain_loss: 3.5893,\tval_loss: 3.8073\n",
            "24:\t[0s / 10s],\t\ttrain_loss: 3.5665,\tval_loss: 3.8026\n",
            "25:\t[0s / 10s],\t\ttrain_loss: 3.5633,\tval_loss: 3.8002\n",
            "26:\t[0s / 10s],\t\ttrain_loss: 3.5826,\tval_loss: 3.7999\n",
            "27:\t[0s / 10s],\t\ttrain_loss: 3.5750,\tval_loss: 3.8047\n",
            "28:\t[0s / 11s],\t\ttrain_loss: 3.5764,\tval_loss: 3.8144\n",
            "29:\t[0s / 11s],\t\ttrain_loss: 3.5599,\tval_loss: 3.8254\n",
            "30:\t[0s / 11s],\t\ttrain_loss: 3.6048,\tval_loss: 3.8346\n",
            "31:\t[0s / 11s],\t\ttrain_loss: 3.6424,\tval_loss: 3.8431\n",
            "32:\t[0s / 11s],\t\ttrain_loss: 3.5988,\tval_loss: 3.8519\n",
            "33:\t[0s / 11s],\t\ttrain_loss: 3.6039,\tval_loss: 3.8641\n",
            "34:\t[0s / 11s],\t\ttrain_loss: 3.6161,\tval_loss: 3.8780\n",
            "35:\t[0s / 11s],\t\ttrain_loss: 3.6208,\tval_loss: 3.8913\n",
            "36:\t[0s / 11s],\t\ttrain_loss: 3.7138,\tval_loss: 3.9137\n",
            "8 / 12\n",
            "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
            "Wall time: 6.2 µs\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 5.5225,\tval_loss: 3.9578\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 6.1269,\tval_loss: 3.9493\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 5.5990,\tval_loss: 3.9492\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 5.1425,\tval_loss: 3.9504\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 5.1792,\tval_loss: 3.9463\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.8983,\tval_loss: 3.9378\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 4.7197,\tval_loss: 3.9267\n",
            "7:\t[0s / 1s],\t\ttrain_loss: 4.6006,\tval_loss: 3.9166\n",
            "8:\t[0s / 1s],\t\ttrain_loss: 4.5049,\tval_loss: 3.9077\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 4.4067,\tval_loss: 3.9006\n",
            "10:\t[0s / 2s],\t\ttrain_loss: 4.2775,\tval_loss: 3.8947\n",
            "11:\t[0s / 2s],\t\ttrain_loss: 4.1457,\tval_loss: 3.8892\n",
            "12:\t[0s / 3s],\t\ttrain_loss: 4.0798,\tval_loss: 3.8818\n",
            "13:\t[0s / 3s],\t\ttrain_loss: 4.0188,\tval_loss: 3.8735\n",
            "14:\t[0s / 4s],\t\ttrain_loss: 3.9371,\tval_loss: 3.8636\n",
            "15:\t[0s / 4s],\t\ttrain_loss: 3.8706,\tval_loss: 3.8518\n",
            "16:\t[0s / 4s],\t\ttrain_loss: 3.8219,\tval_loss: 3.8372\n",
            "17:\t[0s / 4s],\t\ttrain_loss: 3.7702,\tval_loss: 3.8209\n",
            "18:\t[0s / 4s],\t\ttrain_loss: 3.7015,\tval_loss: 3.8041\n",
            "19:\t[0s / 4s],\t\ttrain_loss: 3.6700,\tval_loss: 3.7884\n",
            "20:\t[0s / 4s],\t\ttrain_loss: 3.6244,\tval_loss: 3.7763\n",
            "21:\t[0s / 4s],\t\ttrain_loss: 3.5685,\tval_loss: 3.7712\n",
            "22:\t[0s / 5s],\t\ttrain_loss: 3.5945,\tval_loss: 3.7765\n",
            "23:\t[0s / 5s],\t\ttrain_loss: 3.6466,\tval_loss: 3.7896\n",
            "24:\t[0s / 5s],\t\ttrain_loss: 3.6171,\tval_loss: 3.7999\n",
            "25:\t[0s / 5s],\t\ttrain_loss: 3.6706,\tval_loss: 3.8182\n",
            "26:\t[0s / 5s],\t\ttrain_loss: 3.6584,\tval_loss: 3.8342\n",
            "27:\t[0s / 5s],\t\ttrain_loss: 3.6449,\tval_loss: 3.8464\n",
            "28:\t[0s / 5s],\t\ttrain_loss: 3.6486,\tval_loss: 3.8640\n",
            "29:\t[0s / 5s],\t\ttrain_loss: 3.6839,\tval_loss: 3.8746\n",
            "30:\t[0s / 5s],\t\ttrain_loss: 3.6941,\tval_loss: 3.8864\n",
            "31:\t[0s / 5s],\t\ttrain_loss: 3.6902,\tval_loss: 3.8939\n",
            "9 / 12\n",
            "CPU times: user 2 µs, sys: 1e+03 ns, total: 3 µs\n",
            "Wall time: 5.96 µs\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 5.4836,\tval_loss: 3.9811\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 5.1749,\tval_loss: 3.9773\n",
            "2:\t[0s / 1s],\t\ttrain_loss: 4.9717,\tval_loss: 3.9732\n",
            "3:\t[0s / 1s],\t\ttrain_loss: 4.7860,\tval_loss: 3.9690\n",
            "4:\t[0s / 1s],\t\ttrain_loss: 4.6600,\tval_loss: 3.9641\n",
            "5:\t[0s / 2s],\t\ttrain_loss: 4.5355,\tval_loss: 3.9588\n",
            "6:\t[0s / 2s],\t\ttrain_loss: 4.4137,\tval_loss: 3.9530\n",
            "7:\t[0s / 3s],\t\ttrain_loss: 4.3184,\tval_loss: 3.9464\n",
            "8:\t[0s / 3s],\t\ttrain_loss: 4.2257,\tval_loss: 3.9390\n",
            "9:\t[0s / 3s],\t\ttrain_loss: 4.1614,\tval_loss: 3.9306\n",
            "10:\t[0s / 3s],\t\ttrain_loss: 4.0748,\tval_loss: 3.9216\n",
            "11:\t[0s / 3s],\t\ttrain_loss: 4.0043,\tval_loss: 3.9117\n",
            "12:\t[0s / 4s],\t\ttrain_loss: 3.9375,\tval_loss: 3.9013\n",
            "13:\t[0s / 4s],\t\ttrain_loss: 3.8905,\tval_loss: 3.8900\n",
            "14:\t[0s / 4s],\t\ttrain_loss: 3.8429,\tval_loss: 3.8779\n",
            "15:\t[0s / 4s],\t\ttrain_loss: 3.7888,\tval_loss: 3.8660\n",
            "16:\t[0s / 4s],\t\ttrain_loss: 3.8207,\tval_loss: 3.8533\n",
            "17:\t[0s / 4s],\t\ttrain_loss: 3.7851,\tval_loss: 3.8406\n",
            "18:\t[0s / 4s],\t\ttrain_loss: 3.7331,\tval_loss: 3.8281\n",
            "19:\t[0s / 4s],\t\ttrain_loss: 3.6575,\tval_loss: 3.8164\n",
            "20:\t[0s / 5s],\t\ttrain_loss: 3.6229,\tval_loss: 3.8055\n",
            "21:\t[0s / 5s],\t\ttrain_loss: 3.6019,\tval_loss: 3.7955\n",
            "22:\t[0s / 5s],\t\ttrain_loss: 3.6144,\tval_loss: 3.7875\n",
            "23:\t[0s / 6s],\t\ttrain_loss: 3.5890,\tval_loss: 3.7806\n",
            "24:\t[0s / 6s],\t\ttrain_loss: 3.5670,\tval_loss: 3.7741\n",
            "25:\t[0s / 7s],\t\ttrain_loss: 3.5824,\tval_loss: 3.7709\n",
            "26:\t[0s / 7s],\t\ttrain_loss: 3.5886,\tval_loss: 3.7700\n",
            "27:\t[0s / 8s],\t\ttrain_loss: 3.5750,\tval_loss: 3.7674\n",
            "28:\t[0s / 8s],\t\ttrain_loss: 3.7240,\tval_loss: 3.7690\n",
            "29:\t[0s / 8s],\t\ttrain_loss: 3.6153,\tval_loss: 3.7751\n",
            "30:\t[0s / 8s],\t\ttrain_loss: 3.6258,\tval_loss: 3.7842\n",
            "31:\t[0s / 8s],\t\ttrain_loss: 3.6046,\tval_loss: 3.7959\n",
            "32:\t[0s / 8s],\t\ttrain_loss: 3.7097,\tval_loss: 3.8085\n",
            "33:\t[0s / 8s],\t\ttrain_loss: 3.6275,\tval_loss: 3.8265\n",
            "34:\t[0s / 8s],\t\ttrain_loss: 3.6348,\tval_loss: 3.8457\n",
            "35:\t[0s / 8s],\t\ttrain_loss: 3.6672,\tval_loss: 3.8657\n",
            "36:\t[0s / 8s],\t\ttrain_loss: 3.6467,\tval_loss: 3.8850\n",
            "37:\t[0s / 8s],\t\ttrain_loss: 3.6908,\tval_loss: 3.9064\n",
            "10 / 12\n",
            "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
            "Wall time: 6.91 µs\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 5.4542,\tval_loss: 3.9784\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 5.0372,\tval_loss: 3.9732\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 4.7814,\tval_loss: 3.9676\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 4.5845,\tval_loss: 3.9616\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 4.3703,\tval_loss: 3.9549\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 4.2250,\tval_loss: 3.9470\n",
            "6:\t[0s / 1s],\t\ttrain_loss: 4.0989,\tval_loss: 3.9379\n",
            "7:\t[0s / 1s],\t\ttrain_loss: 3.9971,\tval_loss: 3.9275\n",
            "8:\t[0s / 1s],\t\ttrain_loss: 3.8936,\tval_loss: 3.9162\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 3.8073,\tval_loss: 3.9041\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 3.7485,\tval_loss: 3.8914\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 3.6840,\tval_loss: 3.8785\n",
            "12:\t[0s / 1s],\t\ttrain_loss: 3.6904,\tval_loss: 3.8661\n",
            "13:\t[0s / 2s],\t\ttrain_loss: 3.6249,\tval_loss: 3.8546\n",
            "14:\t[0s / 2s],\t\ttrain_loss: 3.5981,\tval_loss: 3.8437\n",
            "15:\t[0s / 2s],\t\ttrain_loss: 3.6034,\tval_loss: 3.8335\n",
            "16:\t[0s / 3s],\t\ttrain_loss: 3.6886,\tval_loss: 3.8248\n",
            "17:\t[0s / 3s],\t\ttrain_loss: 3.6950,\tval_loss: 3.8178\n",
            "18:\t[1s / 4s],\t\ttrain_loss: 3.7289,\tval_loss: 3.8110\n",
            "19:\t[0s / 4s],\t\ttrain_loss: 3.7120,\tval_loss: 3.8047\n",
            "20:\t[0s / 5s],\t\ttrain_loss: 3.7475,\tval_loss: 3.7972\n",
            "21:\t[1s / 6s],\t\ttrain_loss: 3.6874,\tval_loss: 3.7896\n",
            "22:\t[0s / 6s],\t\ttrain_loss: 3.6701,\tval_loss: 3.7837\n",
            "23:\t[0s / 6s],\t\ttrain_loss: 3.7081,\tval_loss: 3.7811\n",
            "24:\t[1s / 7s],\t\ttrain_loss: 3.7459,\tval_loss: 3.7809\n",
            "25:\t[0s / 7s],\t\ttrain_loss: 3.7254,\tval_loss: 3.7823\n",
            "26:\t[0s / 7s],\t\ttrain_loss: 3.7633,\tval_loss: 3.7811\n",
            "27:\t[0s / 7s],\t\ttrain_loss: 3.7332,\tval_loss: 3.7810\n",
            "28:\t[0s / 7s],\t\ttrain_loss: 3.7200,\tval_loss: 3.7824\n",
            "29:\t[0s / 7s],\t\ttrain_loss: 3.7478,\tval_loss: 3.7828\n",
            "30:\t[0s / 7s],\t\ttrain_loss: 3.7222,\tval_loss: 3.7822\n",
            "31:\t[0s / 7s],\t\ttrain_loss: 3.7997,\tval_loss: 3.7828\n",
            "32:\t[0s / 8s],\t\ttrain_loss: 3.7362,\tval_loss: 3.7858\n",
            "33:\t[0s / 8s],\t\ttrain_loss: 3.7340,\tval_loss: 3.7880\n",
            "34:\t[0s / 8s],\t\ttrain_loss: 3.7996,\tval_loss: 3.7924\n",
            "11 / 12\n",
            "CPU times: user 4 µs, sys: 1 µs, total: 5 µs\n",
            "Wall time: 10.5 µs\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 5.5279,\tval_loss: 3.9320\n",
            "1:\t[1s / 1s],\t\ttrain_loss: 8.2404,\tval_loss: 3.9208\n",
            "2:\t[0s / 1s],\t\ttrain_loss: 7.7359,\tval_loss: 3.9211\n",
            "3:\t[0s / 1s],\t\ttrain_loss: 7.3005,\tval_loss: 3.9240\n",
            "4:\t[0s / 1s],\t\ttrain_loss: 6.9910,\tval_loss: 3.9272\n",
            "5:\t[0s / 1s],\t\ttrain_loss: 6.5788,\tval_loss: 3.9309\n",
            "6:\t[0s / 1s],\t\ttrain_loss: 6.1531,\tval_loss: 3.9368\n",
            "7:\t[0s / 1s],\t\ttrain_loss: 5.6093,\tval_loss: 3.9387\n",
            "8:\t[0s / 1s],\t\ttrain_loss: 5.3248,\tval_loss: 3.9405\n",
            "9:\t[0s / 1s],\t\ttrain_loss: 5.0859,\tval_loss: 3.9415\n",
            "10:\t[0s / 1s],\t\ttrain_loss: 4.9616,\tval_loss: 3.9424\n",
            "11:\t[0s / 1s],\t\ttrain_loss: 4.7966,\tval_loss: 3.9422\n",
            "12 / 12\n",
            "CPU times: user 5 µs, sys: 0 ns, total: 5 µs\n",
            "Wall time: 9.54 µs\n",
            "0:\t[0s / 0s],\t\ttrain_loss: 5.5133,\tval_loss: 3.9770\n",
            "1:\t[1s / 1s],\t\ttrain_loss: 5.0725,\tval_loss: 3.9718\n",
            "2:\t[1s / 2s],\t\ttrain_loss: 4.8041,\tval_loss: 3.9660\n",
            "3:\t[0s / 2s],\t\ttrain_loss: 4.5965,\tval_loss: 3.9591\n",
            "4:\t[0s / 2s],\t\ttrain_loss: 4.3984,\tval_loss: 3.9515\n",
            "5:\t[0s / 2s],\t\ttrain_loss: 4.2432,\tval_loss: 3.9434\n",
            "6:\t[0s / 2s],\t\ttrain_loss: 4.1072,\tval_loss: 3.9344\n",
            "7:\t[0s / 2s],\t\ttrain_loss: 4.0023,\tval_loss: 3.9244\n",
            "8:\t[0s / 3s],\t\ttrain_loss: 3.9099,\tval_loss: 3.9136\n",
            "9:\t[0s / 3s],\t\ttrain_loss: 3.8274,\tval_loss: 3.9017\n",
            "10:\t[0s / 3s],\t\ttrain_loss: 3.7660,\tval_loss: 3.8891\n",
            "11:\t[0s / 3s],\t\ttrain_loss: 3.7063,\tval_loss: 3.8756\n",
            "12:\t[0s / 3s],\t\ttrain_loss: 3.6655,\tval_loss: 3.8628\n",
            "13:\t[0s / 3s],\t\ttrain_loss: 3.6329,\tval_loss: 3.8506\n",
            "14:\t[0s / 3s],\t\ttrain_loss: 3.6313,\tval_loss: 3.8390\n",
            "15:\t[0s / 3s],\t\ttrain_loss: 3.7275,\tval_loss: 3.8299\n",
            "16:\t[0s / 4s],\t\ttrain_loss: 3.7051,\tval_loss: 3.8202\n",
            "17:\t[5s / 9s],\t\ttrain_loss: 3.7539,\tval_loss: 3.8119\n",
            "18:\t[0s / 10s],\t\ttrain_loss: 3.6266,\tval_loss: 3.8052\n",
            "19:\t[1s / 11s],\t\ttrain_loss: 3.6874,\tval_loss: 3.7992\n",
            "20:\t[1s / 12s],\t\ttrain_loss: 3.6431,\tval_loss: 3.7964\n",
            "21:\t[1s / 13s],\t\ttrain_loss: 3.6366,\tval_loss: 3.7928\n",
            "22:\t[0s / 13s],\t\ttrain_loss: 3.6791,\tval_loss: 3.7949\n",
            "23:\t[0s / 13s],\t\ttrain_loss: 3.6737,\tval_loss: 3.7961\n",
            "24:\t[0s / 13s],\t\ttrain_loss: 3.8263,\tval_loss: 3.7992\n",
            "25:\t[0s / 13s],\t\ttrain_loss: 3.9320,\tval_loss: 3.8055\n",
            "26:\t[0s / 13s],\t\ttrain_loss: 3.8709,\tval_loss: 3.8113\n",
            "27:\t[0s / 13s],\t\ttrain_loss: 3.8695,\tval_loss: 3.8165\n",
            "28:\t[0s / 13s],\t\ttrain_loss: 3.7821,\tval_loss: 3.8244\n",
            "29:\t[0s / 13s],\t\ttrain_loss: 3.7486,\tval_loss: 3.8332\n",
            "30:\t[0s / 13s],\t\ttrain_loss: 3.7804,\tval_loss: 3.8437\n",
            "31:\t[0s / 13s],\t\ttrain_loss: 3.7741,\tval_loss: 3.8531\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "keho7amdxDPt"
      },
      "source": [
        "- brier_score가 가장 작은 것부터 정렬\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-vyUqxRtULi"
      },
      "source": [
        "brier_scores.sort()\n",
        "selected_genes = []\n",
        "for i in range(10):\n",
        "  selected_genes.append(brier_scores[0][4][i][1])"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q65Qjo4A3UPF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cefa988b-2b25-4fd9-bd81-fcc91a17c405"
      },
      "source": [
        "gene_count= {}\n",
        "for i in brier_scores:\n",
        "  lst = []\n",
        "  for j in i[4]:\n",
        "    lst.append(j[1])\n",
        "  print(lst)\n",
        "  for k in lst:\n",
        "    if k in gene_count.keys():\n",
        "      gene_count[k] += 1\n",
        "    else:\n",
        "      gene_count[k] = 1\n",
        "sorted(gene_count.items(), key=lambda x: x[1], reverse=True)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['G136', 'G35', 'G60', 'G8', 'G293', 'G123', 'G134', 'G105', 'G132', 'G254']\n",
            "['G115', 'G77', 'G45', 'G186', 'G89', 'G20', 'G203', 'G150', 'G194', 'G276']\n",
            "['G292', 'G161', 'G43', 'G149', 'G35', 'G220', 'G293', 'G263', 'G192', 'G280']\n",
            "['G214', 'G19', 'G211', 'G193', 'G243', 'G140', 'G136', 'G120', 'G105', 'G43']\n",
            "['G137', 'G35', 'G136', 'G196', 'G149', 'G195', 'G158', 'G11', 'G221', 'G19']\n",
            "['G29', 'G299', 'G34', 'G161', 'G271', 'G98', 'G295', 'G241', 'G17', 'G19']\n",
            "['G22', 'G110', 'G192', 'G243', 'G1', 'G260', 'G33', 'G275', 'G149', 'G58']\n",
            "['G35', 'G243', 'G235', 'G161', 'G34', 'G136', 'G254', 'G185', 'G46', 'G195']\n",
            "['G163', 'G85', 'G223', 'G164', 'G281', 'G49', 'G212', 'G148', 'G270', 'G159']\n",
            "['G108', 'G53', 'G150', 'G136', 'G278', 'G235', 'G298', 'G294', 'G35', 'G291']\n",
            "['G6', 'G231', 'G262', 'G295', 'G64', 'G130', 'G138', 'G69', 'G182', 'G70']\n",
            "['G234', 'G175', 'G127', 'G55', 'G75', 'G279', 'G262', 'G230', 'G241', 'G135']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('G136', 5),\n",
              " ('G35', 5),\n",
              " ('G161', 3),\n",
              " ('G149', 3),\n",
              " ('G19', 3),\n",
              " ('G243', 3),\n",
              " ('G293', 2),\n",
              " ('G105', 2),\n",
              " ('G254', 2),\n",
              " ('G150', 2),\n",
              " ('G43', 2),\n",
              " ('G192', 2),\n",
              " ('G195', 2),\n",
              " ('G34', 2),\n",
              " ('G295', 2),\n",
              " ('G241', 2),\n",
              " ('G235', 2),\n",
              " ('G262', 2),\n",
              " ('G60', 1),\n",
              " ('G8', 1),\n",
              " ('G123', 1),\n",
              " ('G134', 1),\n",
              " ('G132', 1),\n",
              " ('G115', 1),\n",
              " ('G77', 1),\n",
              " ('G45', 1),\n",
              " ('G186', 1),\n",
              " ('G89', 1),\n",
              " ('G20', 1),\n",
              " ('G203', 1),\n",
              " ('G194', 1),\n",
              " ('G276', 1),\n",
              " ('G292', 1),\n",
              " ('G220', 1),\n",
              " ('G263', 1),\n",
              " ('G280', 1),\n",
              " ('G214', 1),\n",
              " ('G211', 1),\n",
              " ('G193', 1),\n",
              " ('G140', 1),\n",
              " ('G120', 1),\n",
              " ('G137', 1),\n",
              " ('G196', 1),\n",
              " ('G158', 1),\n",
              " ('G11', 1),\n",
              " ('G221', 1),\n",
              " ('G29', 1),\n",
              " ('G299', 1),\n",
              " ('G271', 1),\n",
              " ('G98', 1),\n",
              " ('G17', 1),\n",
              " ('G22', 1),\n",
              " ('G110', 1),\n",
              " ('G1', 1),\n",
              " ('G260', 1),\n",
              " ('G33', 1),\n",
              " ('G275', 1),\n",
              " ('G58', 1),\n",
              " ('G185', 1),\n",
              " ('G46', 1),\n",
              " ('G163', 1),\n",
              " ('G85', 1),\n",
              " ('G223', 1),\n",
              " ('G164', 1),\n",
              " ('G281', 1),\n",
              " ('G49', 1),\n",
              " ('G212', 1),\n",
              " ('G148', 1),\n",
              " ('G270', 1),\n",
              " ('G159', 1),\n",
              " ('G108', 1),\n",
              " ('G53', 1),\n",
              " ('G278', 1),\n",
              " ('G298', 1),\n",
              " ('G294', 1),\n",
              " ('G291', 1),\n",
              " ('G6', 1),\n",
              " ('G231', 1),\n",
              " ('G64', 1),\n",
              " ('G130', 1),\n",
              " ('G138', 1),\n",
              " ('G69', 1),\n",
              " ('G182', 1),\n",
              " ('G70', 1),\n",
              " ('G234', 1),\n",
              " ('G175', 1),\n",
              " ('G127', 1),\n",
              " ('G55', 1),\n",
              " ('G75', 1),\n",
              " ('G279', 1),\n",
              " ('G230', 1),\n",
              " ('G135', 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yO9ti8SxLPm"
      },
      "source": [
        "- brier_score가 가장 좋은 케이스 출력"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cd2yOAOz5jME",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d23902ac-47be-4f85-9fdc-b3acfbc58edc"
      },
      "source": [
        "print(\"Brier Score :\", brier_scores[0][0])\n",
        "print(\"Hidden Layers :\", brier_scores[0][1])\n",
        "print(\"Number of Nodes :\", brier_scores[0][2])\n",
        "print(\"Learning Rate :\", brier_scores[0][3])\n",
        "print(\"Selection :\", selected_genes)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Brier Score : 0.06959277772719734\n",
            "Hidden Layers : 2\n",
            "Number of Nodes : 2000\n",
            "Learning Rate : 0.001\n",
            "Selection : ['G136', 'G35', 'G60', 'G8', 'G293', 'G123', 'G134', 'G105', 'G132', 'G254']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-mmybRE9XRp"
      },
      "source": [
        "NAN 값을 기준으로 정렬이 끊어진 문제 발견"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPQucTT270bt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a10c0869-8f1b-4eb3-e045-1d3805bdf0df"
      },
      "source": [
        "print(\"brier_score, hidden layer, number of nodes, learning rate\")\n",
        "for i in brier_scores:\n",
        "  print(i[:-1])"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "brier_score, hidden layer, number of nodes, learning rate\n",
            "[0.06959277772719734, 2, 2000, 0.001]\n",
            "[0.07188374275409341, 2, 3000, 0.0001]\n",
            "[0.07222733944452196, 2, 2000, 0.0001]\n",
            "[0.07223506090124863, 1, 2000, 0.002154434690031894]\n",
            "[0.07259161577414139, 1, 3000, 0.000849753435908648]\n",
            "[0.07270541317340544, 1, 3000, 0.001]\n",
            "[0.07287926555825165, 2, 3000, 0.001]\n",
            "[0.07327536200020075, 1, 2000, 0.001]\n",
            "[0.07351248370725726, 1, 3000, 0.0001]\n",
            "[0.07382761547465361, 2, 3000, 0.0001]\n",
            "[0.07440251969320119, 2, 2000, 0.0001]\n",
            "[0.07658301832767403, 1, 2000, 0.0001]\n"
          ]
        }
      ]
    }
  ]
}